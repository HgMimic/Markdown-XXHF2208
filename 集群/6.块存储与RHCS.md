# 块存储

## iSCSI

Internet 小型计算机系统接口 (iSCSI：Internet Small Computer System Interface) Internet 小型计算机系统接口(iSCSI)是一种基于 TCP/IP 的协议，用来建立和管理 IP 存储设备、主机和客户机等之间的相互连接，并创建存储区域网络(SAN)。可将现有 SCSI 接口与以太网络(Ethernet)技术结合，使服务器可与使用 IP 网络的储存装置互相交换资料。

## SAN 和 NAS

### SAN

Storage Area Network 存储区域网络，多采用高速光纤通道，对速率、冗余性要求高。使用 iscsi 存储协议，块级传输。

### NAS

Network Attachment Storage，网络附件存储，采用普通以太网，对速率、冗余无特别要求，使用 NFS、CIFS 共享协议，文件级传输。

### SAN 与 NAS 区别

1. SAN 一般特指存储网络的构建方式，NAS 一般特指产品。
2. SAN 有单独的存储网络，NAS 使用现有网络。

家庭网络存储设备：FREENAS，用的是 FREEBSD 系统。

## 构建网络块存储实验（附加 RHCS）

RHCS：Red Hat Cluster Suite 红帽集群套件

RHCS 提供的三个核心功能：高可用集群、LVS 提供负载均衡、GFS 文件系统提供集群存储

RHCS 集群原理：分布式集群管理（CMAN）、锁管理（DLM）、配置文件管理（CCS）、栅设备（FENCE）、高可用服务管理器、集群配置管理工具、GFS

> 从课程内容可以看出 RHCS 不常用了，负载均衡有 LVS 等，高可用有 Keepalived 等，集群存储也有很多解决方案，如 Ceph、Swift 等。

### 实验规划

**！！实验设备全部使用 CentOS6 ！！**

| 主机                | 身份     | 操作                                                                                                     |
| ------------------- | -------- | -------------------------------------------------------------------------------------------------------- |
| Vm1(192.168.43.101) | 服务器   | 添加硬盘（底层可能是 RAID），可分区，lvm，无需格式化文件系统，安装 scsi-target-utils                     |
| Vm2(192.168.43.102) | 客户端 1 | iscsi-initiator-utils，cman，rgmanager，clvm，gfs2 获取网络硬盘设备，lvm，格式化 gfs2 文件系统，文件共享 |
| Vm3(192.168.43.103) | 客户端 2 | 同上                                                                                                     |
| Vm4(192.168.43.104) | 客户端 3 | 同上                                                                                                     |

### 实验步骤

#### 准备步骤

- 解析主机名称（搭建 DNS 或写 hosts 文件）
- 各配置免密码验证（之后可以通过 ssh 循环脚本实现批量执行命令）
- 搭建时间服务器（实现四台机器之间的时间偏移尽量低）

#### 具体实验步骤

1. 解析主机名（通过 hosts 文件实现），并将文件传给三个客户端（scp 命令）

   ```bash
   vim /etc/hosts
      192.168.43.101 target.test.com target
      192.168.43.102 node1.test.com node1
      192.168.43.103 node2.test.com node2
      192.168.43.104 node3.test.com node3
      #IP 域名 别名
   # 然后可以重启或者分别执行hostname命令修改主机名并重新登录
   hostname target.test.com
   ```

2. 实现 ssh 免密验证

   ```bash
   ssh-keygen -t rsa
   ssh-copy-id node123
   # 可实现操作以上命令的设备对密钥发送到的设备免密登录
   ```

3. 时间服务器设置

   ```bash
   yum install ntp
    # 如果最小化安装，则没有ntp

   ######## 修改服务器作为时间同步服务器 ########
   vim /etc/ntp.conf
      restrict 192.168.43.0 mask 255.255.255.0 nomodify notrap
      # 允许指定网段客户端来同步时间，不允许修改和抓包
      server 127.127.1.0
      # 将本机作为时间同步服务器
      fudge 127.127.1.0 stratum 10
      # fudge设置时间服务器层级，0最高；stratum 10 通常用于给局域网主机提供时间服务

   ######## 修改客户端时间同步设置 ########
   vim /etc/ntp.conf
      server 192.168.43.101
      # 注释掉原有的server项，仅通过局域网定期同步
      restrict 192.168.153.10 nomodify notrap
      # 设置权限

   ntpdate -u 192.168.43.101
   # 手动同步时间

   service ntpd start
   chkconfig ntpd on
   # 启动&自启动ntpd服务
   ```

4. 通过 脚本 + 命令别名 ，实现简单的批量远程执行命令脚本

   ```bash
   vim /root/pl.sh
   # 写一个脚本

      #!/bin/bash
      for i in $(cat /root/ssh_hosts)
      do
         ssh i "$1";
      done

   chmod +x /root/pl.sh

   vim /root/ssh_hosts
   # 写提供给脚本的主机名列表
      node1
      node2
      node3

   alias pl=/root/pl.sh
   # 之后执行pl即可执行该脚本执行批量命令操作
   # $ pl '要执行的命令'
   ```

5. 服务器添加硬盘，进行 lvm，安装 scsi-target-utils

   ```bash
   pvcreate /dev/sdb
   pvcreate /dev/sdc
   vgcreate vg0 /dev/sdb /dev/sdc
   lvcreate -L 15G -n lv0 vg0
   # 创建lvm物理卷、卷组、逻辑卷

   yum install scsi-target-utils

   vim /etc/tgt/targets.conf
      <target iqn.2023-02.com.test:vg0.lv0>
         <backing-store /dev/vg0/lv0>
            vendor_id test
            lun 1
         </backing-store>
         incominguser user1 123456
         initiator-address 192.168.43.0/24
      </target>
   # 编辑配置文件，写入要共享的磁盘和权限认证等，创建iqn共享标签
   service tgtd start
   # 启动tgtd服务
   tgtadm -L iscsi -o show -m target
   # 检查本机对外共享的资源，注意确认大小，分享路径，权限等是否正确
   ```

6. 客户端安装 iscsi-initiator-utils，对服务器共享的块资源进行挂载

   ```bash
   yum install iscsi-initiator-utils
   vim /etc/iscsi/initiatorname.iscsi
      node.session.auth.authmethod = CHAP
      # 取消注释，设置认证方式为CHAP
      node.session.auth.username = user1
      node.session.auth.password = 123456
      # 填写服务器iqn标签中指定的用户名和密码

   iscsiadm -m discovery -t sendtargets -p target
   # 通过此命令查看target主机共享的存储资源，以iqn标签展示出来
   iscsiadm -m node -T iqn.2023-02.com.test:vg0.lv0 --login
   # 通过此命令执行登录动作，将指定标签代表的资源挂载到本地
   lsblk
   # 此时可看到客户端上多出一块硬盘
   ```

7. 客户端安装集群套件及配置

   ```bash
   yum install cman rgmanager

   ccs_tool create cluster_test
   # 创建集群，该名称后面gfs2会用到
   ccs_tool addfence meatware fence_manual
   # 增加fence，实现故障隔离可用性
   ccs_tool lsfence
   # 可查看fence列表
   ccs_tool addnode -n 1 -f meatware node1.test.com
   ccs_tool addnode -n 2 -f meatware node2.test.com
   ccs_tool addnode -n 3 -f meatware node3.test.com
   # 为集群添加节点，指定三个客户端作为节点
   ccs_tool lsnode
   # 可查看node列表
   # 以上 ccs_tool 命令会写入配置文件/etc/cluster.conf（实际上是xml格式文件）
   # 需要将生成的/etc/cluster.conf传给另两台node

   service NetworkManager stop
   chkconfig NetworkManager off
   # 启动cman前需要关闭NetworkManager服务启动&自启动

   vim /etc/sysconfig/cman
      CMAN_QUORUM_TIMEOUT=0
      #修改超时为0，否则cman启动会报错

   ######## 三台node都修改了上述内容后，再启动cman ########
   service cman start
   ```

8. clvm 安装与配置

   ```bash
   yum install lvm2-cluster
   lvmconf --enable-cluster
   # 开启集群lvm
   service clvmd start
   # 开启clvmd 服务

   ######## 在任意一个节点上执行lvm操作，将会同步到所有集群节点 ########
   pvcreate /dev/sdb
   vgcreate cvg0 /dev/sdb
   lvcreate -L 14G -n clv0 cvg0
   # 执行后，其他节点也会看到创建的集群逻辑卷
   ```

9. gfs2 安装与配置

   ```bash
   yum install gfs2-utils

   mkfs.gfs2 -j 3 -p lock_dlm -t cluster_test:anyname /dev/cvg0/clv0
   # 创建gfs2文件系统，注意之前ccs创建的集群名cluster_test在这里必须一致
   # 只需在一台节点上格式化，其他节点都可用

   mount -t gfs2 /dev/cvg0/clv0 /mnt/anyname
   # 挂载使用，文件系统三个节点同步
   ```

10. 扩容上述集群块存储步骤

> 我步骤是这样：
>
> 1. umount 卸载客户端的挂载
> 2. logout 掉 target 服务器的块存储
> 3. target 服务器这边通过 lvm 正常扩容，服务器没格式化过，所以扩容之后也没管
> 4. 重启一下服务器 tgtd 进程
> 5. 客户端现在 login 会把块设备识别成一个新设备，clvm 信息会丢，所以先全都重启一下
> 6. 重启之后 login 块设备，这回识别正常，但是 pv 大小没变
> 7. 需要执行 pvresize 更新大小
> 8. pv 大小更新了，vg 就不用动了，正常扩容一下 lv
> 9. 扩容 lv 之后，需要先挂载到系统上（我在这步没挂载，一直提示没有目录）
> 10. 执行 gfs2_grow /dev/clvm1/wwwdata
> 11. 扩容成功
